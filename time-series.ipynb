{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import warnings\n",
    "import rasterio as rio\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from pyhdf.SD import SD, SDC\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset('C:\\\\Users\\\\Elle\\\\Downloads\\\\ndvi3g_geo_v1_1985_0712.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_dem_path = 'C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\lower_scaled_gfsad.tif'\n",
    "with rio.open(lidar_dem_path) as lidar_dem:\n",
    "    im_array = lidar_dem.read()\n",
    "    lidar_dem.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6241070 66.88\n",
      "1 27721 0.3\n",
      "2 16840 0.18\n",
      "3 33168 0.36\n",
      "4 118782 1.27\n",
      "5 117480 1.26\n",
      "6 54815 0.59\n",
      "7 125240 1.34\n",
      "8 208092 2.23\n",
      "9 2387992 25.59\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, np.count_nonzero(im_array == i), round(np.count_nonzero(im_array == i)/(4320*2160)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702138\n"
     ]
    }
   ],
   "source": [
    "# Get a list of cropland and their classes\n",
    "im_array = im_array.reshape((2160,4320))\n",
    "\n",
    "def apply_mask(pixel):\n",
    "    if pixel == 9:\n",
    "        return 0\n",
    "    else:\n",
    "        return pixel\n",
    "\n",
    "filter_function = np.vectorize(apply_mask)\n",
    "unmasked_pixels = filter_function(im_array)\n",
    "\n",
    "land_pixels = np.nonzero(unmasked_pixels) \n",
    "# print(np.unique(imarray))\n",
    "land_pixel_classes = im_array[land_pixels].tolist()\n",
    "print(len(land_pixel_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702138, 2)\n"
     ]
    }
   ],
   "source": [
    "land_indices = land_pixels \n",
    "non_zero_indices = np.array(land_indices)\n",
    "clean_frame = non_zero_indices.T\n",
    "print(clean_frame.shape)\n",
    "n = clean_frame.shape[0]\n",
    "non_zeros = np.nonzero(im_array)\n",
    "\n",
    "clean_frame_2 = clean_frame \n",
    "clean_frame_df = pd.DataFrame({'lon': clean_frame[:,0], 'lat': clean_frame[:,1]})\n",
    "clean_frame_df['labels'] = land_pixel_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>2469</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>295</td>\n",
       "      <td>2467</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>295</td>\n",
       "      <td>2468</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>2466</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>2467</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702133</td>\n",
       "      <td>1745</td>\n",
       "      <td>1328</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702134</td>\n",
       "      <td>1745</td>\n",
       "      <td>1334</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702135</td>\n",
       "      <td>1745</td>\n",
       "      <td>1339</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702136</td>\n",
       "      <td>1745</td>\n",
       "      <td>1340</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702137</td>\n",
       "      <td>1745</td>\n",
       "      <td>1341</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>702138 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lon   lat  labels\n",
       "0        294  2469       8\n",
       "1        295  2467       8\n",
       "2        295  2468       8\n",
       "3        300  2466       8\n",
       "4        300  2467       8\n",
       "...      ...   ...     ...\n",
       "702133  1745  1328       8\n",
       "702134  1745  1334       8\n",
       "702135  1745  1339       8\n",
       "702136  1745  1340       8\n",
       "702137  1745  1341       8\n",
       "\n",
       "[702138 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tifs = ['1985', '1990', '1995', '2000', '2005']\n",
    "years = ['1985', '1990', '1995', '2000', '2005', '2010', '2015']\n",
    "lidar_dem_path = 'C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\1985.tif'\n",
    "times_series_labels = np.zeros((5, 2160, 4320))\n",
    "for i in range(len(tifs)):\n",
    "    lidar_dem_path = 'C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\' + tifs[i] +'.tif'\n",
    "    with rio.open(lidar_dem_path) as lidar_dem:\n",
    "        array = lidar_dem.read() \n",
    "        array = array.reshape(2160, 4320)\n",
    "        clean_frame_df[str(tifs[i])] = array[land_indices].reshape(n,1)\n",
    "\n",
    "times_series_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>1985</th>\n",
       "      <th>1990</th>\n",
       "      <th>1995</th>\n",
       "      <th>2000</th>\n",
       "      <th>2005</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10944</td>\n",
       "      <td>10944</td>\n",
       "      <td>10944</td>\n",
       "      <td>10944</td>\n",
       "      <td>10944</td>\n",
       "      <td>10944</td>\n",
       "      <td>10944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6774</td>\n",
       "      <td>6774</td>\n",
       "      <td>6774</td>\n",
       "      <td>6774</td>\n",
       "      <td>6774</td>\n",
       "      <td>6774</td>\n",
       "      <td>6774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8528</td>\n",
       "      <td>8528</td>\n",
       "      <td>8528</td>\n",
       "      <td>8528</td>\n",
       "      <td>8528</td>\n",
       "      <td>8528</td>\n",
       "      <td>8528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2280</td>\n",
       "      <td>2280</td>\n",
       "      <td>2280</td>\n",
       "      <td>2280</td>\n",
       "      <td>2280</td>\n",
       "      <td>2280</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1718</td>\n",
       "      <td>1718</td>\n",
       "      <td>1718</td>\n",
       "      <td>1718</td>\n",
       "      <td>1718</td>\n",
       "      <td>1718</td>\n",
       "      <td>1718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lon    lat   1985   1990   1995   2000   2005\n",
       "labels                                                 \n",
       "1       10944  10944  10944  10944  10944  10944  10944\n",
       "2        6774   6774   6774   6774   6774   6774   6774\n",
       "3        8528   8528   8528   8528   8528   8528   8528\n",
       "4        2280   2280   2280   2280   2280   2280   2280\n",
       "5        1718   1718   1718   1718   1718   1718   1718\n",
       "6         495    495    495    495    495    495    495\n",
       "7        4680   4680   4680   4680   4680   4680   4680\n",
       "8        1456   1456   1456   1456   1456   1456   1456"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df[clean_frame_df['1985']>2000].groupby(['labels']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_frame_df[['labels','1985', '1990', '1995', '2000', '2005']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels     8.000\n",
       "1985      65.040\n",
       "1990      73.682\n",
       "1995      78.392\n",
       "2000      79.313\n",
       "2005      83.540\n",
       "Name: 0.75, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['labels']>3].quantile(.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lon        598.000\n",
       "lat       2701.000\n",
       "labels       1.000\n",
       "1985        50.897\n",
       "1990        81.681\n",
       "1995       107.460\n",
       "2000       125.600\n",
       "2005       133.300\n",
       "Name: 0.25, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df[df['labels']<4].quantile(.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_85, df_90, df_95, df_00, df_05, df_10, df_15  =  pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "\n",
    "df_lists = [df_85, df_90, df_95, df_00, df_05, df_10, df_15]\n",
    "\n",
    "for i in range(len(df_lists)):\n",
    "    df_lists[i]['lat'] = clean_frame_df['lat']\n",
    "    df_lists[i]['lon'] = clean_frame_df['lon']\n",
    "    if i < 5:\n",
    "        df_lists[i]['labels'] = clean_frame_df[tifs[i]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_lists[:5])):\n",
    "    df_lists[i]['year'] = years[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elle\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: WARNING: valid_range not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "measures = ['max_y1', 'min_y1', 'mean_y1', 'var_y1', 'max_y2', 'min_y2', 'mean_y2', 'var_y2']\n",
    "ndvi_list = os.listdir('C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\data\\\\ndvi')\n",
    "def retrieve_ndvi(indices, length, year):\n",
    "            path = 'C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\data\\\\ndvi\\\\ndvi3g_geo_v1_'\n",
    "            file_1h = path + year + '_0106.nc4'\n",
    "            file_2h = path + year + '_0712.nc4' \n",
    "            ds_1, ds_2 = np.array(Dataset(file_1h)['ndvi']) , np.array(Dataset(file_2h)['ndvi'])\n",
    "            max_y1 = np.max(ds_1, axis = 0)[indices].reshape(length,1)\n",
    "            min_y1 = np.min(ds_1, axis = 0)[indices].reshape(length,1)\n",
    "            var_y1 = np.var(ds_1, axis = 0)[indices].reshape(length,1)\n",
    "            mean_y1= np.mean(ds_1, axis = 0)[indices].reshape(length,1)\n",
    "            max_y2 = np.max(ds_2, axis = 0)[indices].reshape(length,1)\n",
    "            min_y2 = np.min(ds_2, axis = 0)[indices].reshape(length,1)\n",
    "            var_y2 = np.var(ds_2, axis = 0)[indices].reshape(length,1)\n",
    "            mean_y2 = np.mean(ds_2, axis = 0)[indices].reshape(length,1)\n",
    "            return max_y1, min_y1, mean_y1, var_y1, max_y2, min_y2, mean_y2, var_y2\n",
    "\n",
    "for i in range(len(df_lists)):\n",
    "    df_lists[i]['max_y1_ndvi'], df_lists[i]['min_y1_ndvi'], df_lists[i]['mean_y1_ndvi'], df_lists[i]['var_y1_ndvi'], df_lists[i]['max_y2_ndvi'], df_lists[i]['min_y2_ndvi'], df_lists[i]['mean_y2_ndvi'], df_lists[i]['var_y2_ndvi'] = retrieve_ndvi(land_indices, n, years[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702138\n"
     ]
    }
   ],
   "source": [
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aet,0\n",
      "aet,1\n",
      "aet,2\n",
      "aet,3\n",
      "aet,4\n",
      "aet,5\n",
      "aet,6\n",
      "def,0\n",
      "def,1\n",
      "def,2\n",
      "def,3\n",
      "def,4\n",
      "def,5\n",
      "def,6\n",
      "PDSI,0\n",
      "PDSI,1\n",
      "PDSI,2\n",
      "PDSI,3\n",
      "PDSI,4\n",
      "PDSI,5\n",
      "PDSI,6\n",
      "pet,0\n",
      "pet,1\n",
      "pet,2\n",
      "pet,3\n",
      "pet,4\n",
      "pet,5\n",
      "pet,6\n",
      "ppt,0\n",
      "ppt,1\n",
      "ppt,2\n",
      "ppt,3\n",
      "ppt,4\n",
      "ppt,5\n",
      "ppt,6\n",
      "q,0\n",
      "q,1\n",
      "q,2\n",
      "q,3\n",
      "q,4\n",
      "q,5\n",
      "q,6\n",
      "soil,0\n",
      "soil,1\n",
      "soil,2\n",
      "soil,3\n",
      "soil,4\n",
      "soil,5\n",
      "soil,6\n",
      "srad,0\n",
      "srad,1\n",
      "srad,2\n",
      "srad,3\n",
      "srad,4\n",
      "srad,5\n",
      "srad,6\n",
      "tmax,0\n",
      "tmax,1\n",
      "tmax,2\n",
      "tmax,3\n",
      "tmax,4\n",
      "tmax,5\n",
      "tmax,6\n",
      "tmin,0\n",
      "tmin,1\n",
      "tmin,2\n",
      "tmin,3\n",
      "tmin,4\n",
      "tmin,5\n",
      "tmin,6\n",
      "vap,0\n",
      "vap,1\n",
      "vap,2\n",
      "vap,3\n",
      "vap,4\n",
      "vap,5\n",
      "vap,6\n",
      "vpd,0\n",
      "vpd,1\n",
      "vpd,2\n",
      "vpd,3\n",
      "vpd,4\n",
      "vpd,5\n",
      "vpd,6\n",
      "ws,0\n",
      "ws,1\n",
      "ws,2\n",
      "ws,3\n",
      "ws,4\n",
      "ws,5\n",
      "ws,6\n"
     ]
    }
   ],
   "source": [
    "measures = ['aet', 'def', 'PDSI', 'pet', 'ppt', 'q', 'soil', 'srad', 'tmax', 'tmin', 'vap', 'vpd', 'ws'] \n",
    "\n",
    "def extract_nc(indices, length, year, variable):\n",
    "    path = 'C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\data\\\\climate\\\\' + year + '\\\\'\n",
    "    full_path = path + 'TerraClimate_' + variable +'_' + year + '.nc'\n",
    "    ds = np.array(Dataset(full_path)[variable])\n",
    "    max_y1 = np.max(ds, axis = 0)\n",
    "    min_y1 = np.min(ds, axis = 0)\n",
    "    var_y1 = np.var(ds, axis = 0)\n",
    "    mean_y1 = np.mean(ds, axis = 0)\n",
    "    max_y1 = resize(max_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    min_y1 = resize(min_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    var_y1 = resize(var_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    mean_y1 = resize(mean_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    return max_y1, min_y1, var_y1, mean_y1\n",
    "\n",
    "\n",
    "for i in measures:\n",
    "    for j in range(len(df_lists)):\n",
    "        df_lists[j][i+'_max'], df_lists[j][i+'_min'], df_lists[j][i+'_var'], df_lists[j][i+'_mean'] = extract_nc(land_indices, n, years[j], i)\n",
    "        print(i+\",\"+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_aet.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_def.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_pet.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_ppt.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_q.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_soil.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_srad.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_tmax.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_tmin.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_vap.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_vpd.nc\n",
      "C:\\Users\\Elle\\Documents\\w210\\data\\climate\\lt\\TerraClimate19812010_ws.nc\n"
     ]
    }
   ],
   "source": [
    "measures_2 = ['aet', 'def', 'pet', 'ppt', 'q', 'soil', 'srad', 'tmax', 'tmin', 'vap', 'vpd', 'ws'] \n",
    "\n",
    "def extract_nc_lt(indices, length, variable):\n",
    "    path = 'C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\data\\\\climate\\\\lt\\\\'\n",
    "    full_path = path + 'TerraClimate19812010_' + variable  + '.nc'\n",
    "    print(full_path)\n",
    "    ds = np.array(Dataset(full_path)[variable])\n",
    "    max_y1 = np.max(ds, axis = 0)\n",
    "    min_y1 = np.min(ds, axis = 0)\n",
    "    var_y1 = np.var(ds, axis = 0)\n",
    "    mean_y1= np.mean(ds, axis = 0)\n",
    "    max_y1 = resize(max_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    min_y1 = resize(min_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    var_y1 = resize(var_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    mean_y1 = resize(mean_y1, (2160, 4320))[indices].reshape(length,1)\n",
    "    return max_y1, min_y1, var_y1, mean_y1\n",
    "\n",
    "for i in measures_2:\n",
    "    clean_frame_df[i+'_lt_max'], clean_frame_df[i+'_lt_min'], clean_frame_df[i+'_lt_var'], clean_frame_df[i+'_lt_mean'] = extract_nc_lt(land_indices, n, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in df_lists:\n",
    "    for i in measures_2:\n",
    "        j[i+'_lt_max'] = clean_frame_df[i+'_lt_max'] \n",
    "        j[i+'_lt_min'] = clean_frame_df[i+'_lt_min'] \n",
    "        j[i+'_lt_var'] = clean_frame_df[i+'_lt_var']\n",
    "        j[i+'_lt_mean'] = clean_frame_df[i+'_lt_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([df_85, df_90, df_95, df_00, df_05])\n",
    "len(combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'labels', 'year', 'max_y1_ndvi', 'min_y1_ndvi',\n",
       "       'mean_y1_ndvi', 'var_y1_ndvi', 'max_y2_ndvi', 'min_y2_ndvi',\n",
       "       ...\n",
       "       'vap_lt_var', 'vap_lt_mean', 'vpd_lt_max', 'vpd_lt_min', 'vpd_lt_var',\n",
       "       'vpd_lt_mean', 'ws_lt_max', 'ws_lt_min', 'ws_lt_var', 'ws_lt_mean'],\n",
       "      dtype='object', length=112)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['max_y1_ndvi', 'min_y1_ndvi', 'mean_y1_ndvi', 'var_y1_ndvi', 'max_y2_ndvi', 'min_y2_ndvi', 'mean_y2_ndvi', 'var_y2_ndvi', 'aet_max', 'aet_min', 'aet_var', 'aet_mean', 'def_max', 'def_min', 'def_var', 'def_mean', 'PDSI_max', 'PDSI_min', 'PDSI_var', 'PDSI_mean', 'pet_max', 'pet_min', 'pet_var', 'pet_mean', 'ppt_max', 'ppt_min', 'ppt_var', 'ppt_mean', 'q_max', 'q_min', 'q_var', 'q_mean', 'soil_max', 'soil_min', 'soil_var', 'soil_mean', 'srad_max', 'srad_min', 'srad_var', 'srad_mean', 'tmax_max', 'tmax_min', 'tmax_var', 'tmax_mean', 'tmin_max', 'tmin_min', 'tmin_var', 'tmin_mean', 'vap_max', 'vap_min', 'vap_var', 'vap_mean', 'vpd_max', 'vpd_min', 'vpd_var', 'vpd_mean', 'ws_max', 'ws_min', 'ws_var', 'ws_mean', 'aet_lt_max', 'aet_lt_min', 'aet_lt_var', 'aet_lt_mean', 'def_lt_max', 'def_lt_min', 'def_lt_var', 'def_lt_mean', 'pet_lt_max', 'pet_lt_min', 'pet_lt_var', 'pet_lt_mean', 'ppt_lt_max', 'ppt_lt_min', 'ppt_lt_var', 'ppt_lt_mean', 'q_lt_max', 'q_lt_min', 'q_lt_var', 'q_lt_mean', 'soil_lt_max', 'soil_lt_min', 'soil_lt_var', 'soil_lt_mean', 'srad_lt_max', 'srad_lt_min', 'srad_lt_var', 'srad_lt_mean', 'tmax_lt_max', 'tmax_lt_min', 'tmax_lt_var', 'tmax_lt_mean', 'tmin_lt_max', 'tmin_lt_min', 'tmin_lt_var', 'tmin_lt_mean', 'vap_lt_max', 'vap_lt_min', 'vap_lt_var', 'vap_lt_mean', 'vpd_lt_max', 'vpd_lt_min', 'vpd_lt_var', 'vpd_lt_mean', 'ws_lt_max', 'ws_lt_min', 'ws_lt_var', 'ws_lt_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['irrigated'] = [1 if x > 100 else 0 for x in combined_df['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df['irrigated'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combined_df[features]\n",
    "labels = combined_df['labels']\n",
    "ncores = os.cpu_count()\n",
    "train_data_unb, test_data_unb, train_labels_unb, test_labels_unb = train_test_split(data, labels, test_size=0.3)\n",
    "clf_unb = RandomForestRegressor(n_estimators=40 , min_samples_leaf=2, max_depth=50, n_jobs=ncores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf_unb.fit(train_data_unb, train_labels_unb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=8,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = combined_df[features]\n",
    "labels = combined_df['irrigated']\n",
    "ncores = os.cpu_count()\n",
    "train_data_unb, test_data_unb, train_labels_unb, test_labels_unb = train_test_split(data, labels, test_size=0.3)\n",
    "clf_unb = RandomForestClassifier(n_estimators=40 , min_samples_leaf=2, max_depth=50, n_jobs=ncores)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.01 s\n",
      "acc 0.9452282409820671\n",
      "kappa 0.8630000570858083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96    755689\n",
      "           1       0.92      0.88      0.90    297518\n",
      "\n",
      "    accuracy                           0.95   1053207\n",
      "   macro avg       0.94      0.93      0.93   1053207\n",
      "weighted avg       0.94      0.95      0.94   1053207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time predictions_unb = clf_unb.predict(test_data_unb)\n",
    "print(\"acc\",accuracy_score(test_labels_unb, predictions_unb))\n",
    "print(\"kappa\", cohen_kappa_score(test_labels_unb, predictions_unb))\n",
    "print(classification_report(test_labels_unb, predictions_unb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = combined_df[combined_df['year'] == '2005'], combined_df[combined_df['year'] != '2005']\n",
    "train_irr = train[train['irrigated'] == 1]\n",
    "train_non = train[train['irrigated'] == 0]\n",
    "train_non = train_non.sample(frac=0.5, replace=False, random_state=1)\n",
    "train = pd.concat([train_irr, train_non])\n",
    "test_labels, train_labels = test['irrigated'], train['irrigated']\n",
    "test_data, train_data = test[features], train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=2, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=8,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_unb = ExtraTreesClassifier(n_estimators=200, min_samples_leaf=2, max_depth=50, n_jobs=ncores)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "%time clf_unb.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n",
      "acc 0.9153841552515317\n",
      "kappa 0.79504236774018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94    496369\n",
      "           1       0.86      0.85      0.85    205769\n",
      "\n",
      "    accuracy                           0.92    702138\n",
      "   macro avg       0.90      0.90      0.90    702138\n",
      "weighted avg       0.92      0.92      0.92    702138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time predictions= clf_unb.predict(test_data)\n",
    "print(\"acc\",accuracy_score(test_labels, predictions))\n",
    "print(\"kappa\", cohen_kappa_score(test_labels, predictions))\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_frame_df['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_frame_df['2005_binary'] = [1 if x > 100 else 0 for x in clean_frame_df['2005']]\n",
    "clean_frame_df['2000_binary'] = [1 if x > 100 else 0 for x in clean_frame_df['2000']]\n",
    "clean_frame_df['1995_binary'] = [1 if x > 100 else 0 for x in clean_frame_df['1995']]\n",
    "clean_frame_df['1990_binary'] = [1 if x > 100 else 0 for x in clean_frame_df['1990']]\n",
    "clean_frame_df['1985_binary'] = [1 if x > 100 else 0 for x in clean_frame_df['1985']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203213"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df['predictions'][clean_frame_df['predictions']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_frame_df['predictions'][clean_frame_df['predictions']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203213"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df['predictions'][clean_frame_df['predictions']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205769"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df['2005_binary'][clean_frame_df['2005_binary']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203465"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df['2000_binary'][clean_frame_df['2000_binary']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199211"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df['2005_binary'][clean_frame_df['2005_binary']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_frame_df['2005_binary'][clean_frame_df['2005_binary']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195514"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df['1990_binary'][clean_frame_df['1990_binary']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186986"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_frame_df['1985_binary'][clean_frame_df['1985_binary']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_frame_df['1990_binary'][clean_frame_df['1990_binary']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_frame_df['2000_binary'][clean_frame_df['2000_binary']==1].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>vap_lt_var</td>\n",
       "      <td>0.039653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>tmax_lt_var</td>\n",
       "      <td>0.030931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>srad_lt_var</td>\n",
       "      <td>0.021738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>pet_lt_var</td>\n",
       "      <td>0.018637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>tmin_var</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>vap_var</td>\n",
       "      <td>0.016958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>tmax_lt_max</td>\n",
       "      <td>0.016044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>tmin_lt_var</td>\n",
       "      <td>0.015989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>def_lt_var</td>\n",
       "      <td>0.014926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>tmax_var</td>\n",
       "      <td>0.014882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importances\n",
       "98   vap_lt_var     0.039653\n",
       "90  tmax_lt_var     0.030931\n",
       "86  srad_lt_var     0.021738\n",
       "70   pet_lt_var     0.018637\n",
       "46     tmin_var     0.017236\n",
       "50      vap_var     0.016958\n",
       "88  tmax_lt_max     0.016044\n",
       "94  tmin_lt_var     0.015989\n",
       "66   def_lt_var     0.014926\n",
       "42     tmax_var     0.014882"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_import = pd.DataFrame()\n",
    "df_import['feature'] = features\n",
    "df_import['importances'] = clf_unb.feature_importances_\n",
    "df_import=df_import.sort_values('importances', ascending=False)\n",
    "df_import.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'aet'\n",
    "year = '1985'\n",
    "path = 'C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\data\\\\climate\\\\' + year + '\\\\'\n",
    "full_path = path + 'TerraClimate_' + variable +'_' + year + '.nc'\n",
    "print(full_path)\n",
    "ds = np.array(Dataset(full_path)[variable])\n",
    "max_y1 = np.max(ds, axis = 0)\n",
    "min_y1 = np.min(ds, axis = 0)\n",
    "var_y1 = np.var(ds, axis = 0)\n",
    "mean_y1= np.mean(ds, axis = 0)\n",
    "print(mean_y1.shape)\n",
    "mean = resize(mean_y1, (2160, 4320))\n",
    "print(mean.shape)\n",
    "df_85['mean_aet'] = mean[land_indices]\n",
    "\n",
    "# data = resize(ds, (2160, 4320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lidar_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.array(ds['ndvi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero((test < 1) & (test > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset('C:\\\\Users\\\\Elle\\\\Documents\\\\w210\\\\data\\\\ndvi\\\\ndvi3g_geo_v1_1985_0106.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(ds['ndvi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
